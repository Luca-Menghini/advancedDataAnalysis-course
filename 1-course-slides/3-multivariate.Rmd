---
title: 'ADVANCED DATA ANALYSIS \newline FOR PSYCHOLOGICAL SCIENCE'
subtitle: 'Part 2. Introduction to multivariate modeling'
author:  |
 |
 | **Luca Menghini Ph.D.** \fontsize{9pt}{7.2}\selectfont
 |
 | luca.menghini@unipd.it
 |
 |
 | ***
 | Master degree in Developmental and Educational Psychology 
 |
 | University of Padova
 |
 | 2023-2024
 |
 | ![](img/logo.PNG){width=1.7in}
output:
  beamer_presentation:
    fonttheme: serif
    theme: Singapore
    slide_level: 2
    includes:
      in_header: mystyle.tex
---

## Outline of Part 2

\fontsize{8pt}{12}\selectfont
- **`sem()` intro**: Gentle introduction to the world of structural equation modeling (SEM)

- **Path analysis**: Introduction to path analysis (aka SEM with observed variables) and focus on *mediation models*

- **Data structure**: How to approach a multivariate data structure, how to manipulate and pre-process multivariate data `r fontawesome::fa(name = "r-project", height = "1em")`

- **Model fit & evaluation**: How to fit a path analysis in R, to evaluate model fit, compare multiple models, and interpret model results `r fontawesome::fa(name = "r-project", height = "1em")`

- **`cfa()`**: How to conduct a confirmatory factor analysis (CFA) and to interpret its results `r fontawesome::fa(name = "r-project", height = "1em")`

- \color{blue} **Related topics**: In-depth topics related to multivariate modeling (e.g., cross-lagged panel models, multilevel and Bayesian SEM) `r fontawesome::fa(name = "microscope", fill = "blue", height = "1em")`

___ \newline \fontsize{5pt}{12}\selectfont \color{blue}
`r fontawesome::fa(name = "microscope", fill = "blue", height = "1em")` = not for the exam \color{black} \newline `r fontawesome::fa(name = "r-project", height = "1em")` = exercises with R (bring your laptop!)

# sem() intro

## Multivariate analyses for a multivariate reality

```{r , echo = FALSE, fig.width=12,fig.height=3, warning=FALSE,message=FALSE}
library(ggplot2);library(gridExtra); library(plotly) # loading packages
y <- rnorm(n=50) # y = 50 random values from standard normal distribution
df <- data.frame(y=y, # dataframe to be used in the plot
                 x=y + rnorm(n=50,sd=0.8),
                 z=y - rnorm(n=50,sd=1.2)) # x = y + some random value
grid.arrange(ggplot(df,aes(y)) + geom_histogram() + theme(axis.text=element_blank(),title=element_text(size=18)) +
               ggtitle("Univariate"),
             ggplot(df,aes(x,y)) + geom_point() + theme(axis.text=element_blank(),title=element_text(size=18)) +
               ggtitle("Bivariate"),
             ggplot(df,aes(z,y)) + geom_point() + theme(axis.text=element_blank(),title=element_text(size=18)) +
               ggtitle("Still bivariate"),
             ggplot(df,aes(x,y,color=z)) + geom_point() + 
               theme(axis.text=element_blank(),legend.text = element_blank(),title=element_text(size=18)) +
               scale_color_gradient2(low="white",high="purple") +
               ggtitle("Multivariate"),
             nrow=1)
```

\fontsize{7.5pt}{12}\selectfont

>- In psychology, we mainly inspect empirical data focusing on **univariate** (*y*) \newline or **bivariate** relationships (either *y* by *x* or *y* by *z*)

>- But reality (particularly psychosocial reality) is complex, it is **multivariate** \newline i.e., more than two variables covarying at the same time

>- It is *reductionist* to separately analyze our variables without considering their overall interactions &rightarrow; **biased effect estimates**

>- **Structural equation modeling (SEM)** allow to analyze the relationships of interest by accounting for the multivariate reality of psychosocial phenomena (e.g., *y* by *x* covarying with *z*; *x* affects *y* through *z*)

## Observed indicators & latent variables

```{r , echo = FALSE,fig.width=12,fig.height=3,out.width="280px",fig.align='center'}
knitr::include_graphics("img/latentvars.PNG")
```

\fontsize{7.5pt}{12}\selectfont

>- In psychology, we are mainly interested in **latent variables** = phenomena that we cannot directly observe, but we can estimate from 1+ **observed indicators** (e.g., 10-item scale measuring anxiety)

>- Are we allowed to do that? Yes (let's say yes), provided that we trust the indicator **construct validity** = their relationship with the latent variable they claim to measure

>- **SEM** allow to evaluate that by ***quantifying*** **the latent variables** and their relationships with observed indicators

## Structural what!?

\fontsize{8.5pt}{12}\selectfont \color{violet}
Structural equation modeling (SEM) \newline = multivariate *linear* models formalized by **systems of equations** \newline \color{black}

\begincols
  \begincol{.5\textwidth}

\fontsize{7pt}{12}\selectfont
**Linear models** (LM): determining the link between a dependent and 1+ independent variables through a **single equation** like: \color{violet} $PERF = \beta_1IQ + \beta_2ANX + \epsilon$ \color{black}
```{r echo=FALSE,warning=FALSE,message=FALSE}
library(DiagrammeR); library(DiagrammeRsvg); library(rsvg)

tmp <- grViz(
'digraph boxes_and_circles {
  graph [layout = neato]
  node [shape = box]
  x1 [label = <IQ> pos="-2,0.5!"]
  x2 [label = <ANX> pos="-2,-0.5!"]
  y [label = <PERF> pos="0,0!"]
  node [shape = plaintext]
  e [label = <&epsilon;> pos="1,0!"]
  # edges
  x1->y [label = <&beta;<SUB>1</SUB>>]
  x2->y [label = <&beta;<SUB>2</SUB>>]
  e->y}')

# Convert to SVG, then save as png
tmp = export_svg(tmp)
tmp = charToRaw(tmp) # flatten
rsvg_png(tmp, "img/lm.png") # saved graph as png in current working directory
```
```{r , echo = FALSE, out.width = "130px",fig.align="center"}
knitr::include_graphics("img/lm.png")
```

LM can only predict **one dependent variable at a time**, being either *univariate* (without predictors, i.e., intercept-only) or *bivariate* (with predictors).

  \endcol
\begincol{.5\textwidth}

  \endcol
\endcols

## Structural what!?

\fontsize{8.5pt}{12}\selectfont \color{violet}
Structural equation modeling (SEM) \newline = multivariate *linear* models formalized by **systems of equations** \newline \color{black}

\begincols
  \begincol{.5\textwidth}

\fontsize{7pt}{12}\selectfont
**Linear models** (LM): determining the link between a dependent and 1+ independent variables through a **single equation** like: \color{violet} $PERF = \beta_1IQ + \beta_2ANX + \epsilon$ \color{black}
```{r echo=FALSE,warning=FALSE,message=FALSE}
library(DiagrammeR); library(DiagrammeRsvg); library(rsvg)

tmp <- grViz(
'digraph boxes_and_circles {
  graph [layout = neato]
  node [shape = box]
  x1 [label = <IQ> pos="-2,0.5!"]
  x2 [label = <ANX> pos="-2,-0.5!"]
  y [label = <PERF> pos="0,0!"]
  node [shape = plaintext]
  e [label = <&epsilon;> pos="1,0!"]
  # edges
  x1->y [label = <&beta;<SUB>1</SUB>>]
  x2->y [label = <&beta;<SUB>2</SUB>>]
  e->y}')

# Convert to SVG, then save as png
tmp = export_svg(tmp)
tmp = charToRaw(tmp) # flatten
rsvg_png(tmp, "img/lm.png") # saved graph as png in current working directory
```
```{r , echo = FALSE, out.width = "130px",fig.align="center"}
knitr::include_graphics("img/lm.png")
```

LM can only predict **one dependent variable at a time**, being either *univariate* (without predictors, i.e., intercept-only) or *bivariate* (with predictors).

  \endcol
\begincol{.5\textwidth}

\fontsize{7pt}{12}\selectfont
**SEM** allow to simultaneously model multiple ~~dependent~~ *endogenous* variables \newline with a **system of equations** like: \color{violet}

$$ \begin{cases} ANX = \beta_{1}SEFF + \epsilon_2 \\\\ PERF = \beta_{2}SEFF + \beta_{3}ANX + \epsilon_3 \end{cases} $$

```{r echo=FALSE}
library(DiagrammeR); library(DiagrammeRsvg); library(rsvg)

tmp <- grViz(
'digraph boxes_and_circles {
  graph [layout = neato]
  node [shape = box]
  x1 [label = <SEFF> pos="-2,0!"]
  y2 [label = <ANX> pos="0,0.5!"]
  y3 [label = <PERF> pos="0,-0.5!"]
  node [shape = plaintext]
  e2 [label = <&epsilon;<SUB>2</SUB>> pos="1,0.5!"]
  e3 [label = <&epsilon;<SUB>3</SUB>>pos="1,-0.5!"]
  # edges
  x1->y2 [label = <&beta;<SUB>1</SUB>>]
  x1->y3 [label = <&beta;<SUB>2</SUB>>]
  y2->y3 [label = <&beta;<SUB>3</SUB>>]
  e2->y2
  e3->y3}')

# Convert to SVG, then save as png
tmp = export_svg(tmp)
tmp = charToRaw(tmp) # flatten
rsvg_png(tmp, "img/sem1.png") # saved graph as png in current working directory
```
```{r , echo = FALSE, out.width = "130px",fig.align="center"}
knitr::include_graphics("img/sem1.png")
```

  \endcol
\endcols

## The SEM family

\fontsize{8pt}{12}\selectfont
SEM = broad family of statistical models within which LM, ANOVA, and even correlation can be included.

Particularly, 2 main sub-families can be distinguished based on whether \newline __latent variables__ are included in the model or not: \fontsize{7pt}{12}\selectfont

- __Path analysis__: multivariate linear models with observed variables only

- __Confirmatory factor analysis (CFA)__: multivariate linear models with both observed and latent variables

```{r , echo = FALSE, out.width = "270px",fig.align='center'}
knitr::include_graphics("img/SEMfamily.PNG")
```

\fontsize{5pt}{12}\selectfont Source: Beaujean (2014)

## Path models & path analysis

\fontsize{8pt}{12}\selectfont
**Path models/diagrams** = multivariate models with observed variables only \newline = pictorial representations (*diagrams*) of a theory of variable relationships

```{r , echo = FALSE, out.width = "160px",fig.align="center"}
knitr::include_graphics("img/sem1.png")
```

**Paths** = arrows (*edges*) linking the variables (*nodes*) in a model

**Path analysis** = analysis of multivariate relationships between observed variables ('*quantification of the paths accounting for all other paths and errors*')

## Latent factors & CFA

\begincols
  \begincol{.67\textwidth}
  
\fontsize{7pt}{12}\selectfont

- \color{blue} __Observed/Manifest variable (OV)__ \color{black} \newline variable that is directly observable (e.g., height, heart rate, item responses)

- \color{magenta} __Latent variable/factor (LV)__ \color{black} \newline variable that is *not* directly observable (e.g., anxiety, intelligence), but can be indexed by \newline one or more observed variables

- In SEM, \color{blue}**OV**s \color{black} are represented by \color{blue}squares/rectangles \color{black} and indexed with \color{blue}lower case letters (e.g., *x*)\color{black}, whereas \color{magenta}**LV**s \color{black} are represented by \color{magenta}circles/ellipses \color{black} \newline and indexed by the \color{magenta}Greek letter $\eta$ \color{black}

```{r , echo = FALSE, out.width = "130px"}
knitr::include_graphics("img/latobs.PNG")
```
  
  \endcol
\begincol{.4\textwidth}

  \endcol
\endcols

## Latent factors & CFA

\begincols
  \begincol{.67\textwidth}
  
\fontsize{7pt}{12}\selectfont

- \color{blue} __Observed/Manifest variable (OV)__ \color{black} \newline variable that is directly observable (e.g., height, heart rate, item responses)

- \color{magenta} __Latent variable/factor (LV)__ \color{black} \newline variable that is *not* directly observable (e.g., anxiety, intelligence), but can be indexed by \newline one or more observed variables

- In SEM, \color{blue}**OV**s \color{black} are represented by \color{blue}squares/rectangles \color{black} and indexed with \color{blue}lower case letters (e.g., *x*)\color{black}, whereas \color{magenta}**LV**s \color{black} are represented by \color{magenta}circles/ellipses \color{black} \newline and indexed by the \color{magenta}Greek letter $\eta$ \color{black}

```{r , echo = FALSE, out.width = "130px"}
knitr::include_graphics("img/latobs.PNG")
```
  
  \endcol
\begincol{.4\textwidth}

Confirmatory factor analysis (CFA)

\fontsize{7pt}{12}\selectfont
= analysis of the relationships (*factor loadings*) between a set of OVs and one or more LVs \newline

CFA uses **latent variable models** to *form* or *quantify* LVs \newline and their relationships with OVs \newline (evaluation of **construct validity**) \newline

```{r echo=FALSE,message=FALSE,warning=FALSE, out.width = "100px"}
library(DiagrammeR); library(DiagrammeRsvg); library(rsvg)
tmp <- grViz(
'digraph boxes_and_circles {
  graph [layout = neato]
  node [shape = oval]
  E1 [label = <&eta;<SUB>1</SUB>> pos="0.5,0!", style=filled, fillcolor="#ED028C"]
  node [shape = box]
  x1 [label = <x<SUB>1</SUB>> pos="2,1!", style=filled, fillcolor="#00AEEF"]
  x2 [label = <x<SUB>2</SUB>> pos="2,0!", style=filled, fillcolor="#00AEEF"]
  x3 [label = <x<SUB>3</SUB>> pos="2,-1!", style=filled, fillcolor="#00AEEF"]
  node [shape = plaintext]
  e1 [label = <&epsilon;<SUB>1</SUB>> pos="3,1!"]
  e2 [label = <&epsilon;<SUB>2</SUB>>pos="3,0!"]
  e3 [label = <&epsilon;<SUB>3</SUB>>pos="3,-1!"]
  # edges
  E1->x1 
  E1->x2 
  E1->x3 
  e1->x1
  e2->x2
  e3->x3}')
# Convert to SVG, then save as png
tmp = export_svg(tmp)
tmp = charToRaw(tmp) # flatten
rsvg_png(tmp, "img/sem2.png") # saved graph as png in current working directory
knitr::include_graphics("img/sem2.png")
```

  \endcol
\endcols

## SEM: Measurement & Structural model

\fontsize{7pt}{12}\selectfont
To properly talk about 'full SEM' (or just SEM), we need both OVs and LVs

```{r echo=FALSE,message=FALSE,warning=FALSE}
library(DiagrammeR); library(DiagrammeRsvg); library(rsvg)
tmp <- grViz(
'digraph boxes_and_circles {
  graph [layout = neato]
  node [shape = oval]
  E1 [label = <&eta;<SUB>1</SUB>> pos="-0.5,0!"]
  E2 [label = <&eta;<SUB>2</SUB>> pos="0.5,0!"]
  node [shape = box]
  x1 [label = <x<SUB>1</SUB>> pos="-2,1!"]
  x2 [label = <x<SUB>2</SUB>> pos="-2,0!"]
  x3 [label = <x<SUB>3</SUB>> pos="-2,-1!"]
  x4 [label = <x<SUB>4</SUB>> pos="2,1!"]
  x5 [label = <x<SUB>5</SUB>> pos="2,0!"]
  x6 [label = <x<SUB>6</SUB>> pos="2,-1!"]
  node [shape = plaintext]
  e1 [label = <&epsilon;<SUB>1</SUB>> pos="-3,1!"]
  e2 [label = <&epsilon;<SUB>2</SUB>>pos="-3,0!"]
  e3 [label = <&epsilon;<SUB>2</SUB>>pos="-3,-1!"]
  e4 [label = <&epsilon;<SUB>1</SUB>> pos="3,1!"]
  e5 [label = <&epsilon;<SUB>2</SUB>>pos="3,0!"]
  e6 [label = <&epsilon;<SUB>2</SUB>>pos="3,-1!"]
  z2 [label = <&zeta;<SUB>2</SUB>>pos="0.5,0.8!"]
  # edges
  E1->x1 [color="#ED028C"]
  E1->x2 [color="#ED028C"] 
  E1->x3 [color="#ED028C"]
  E2->x4 [color="#ED028C"]
  E2->x5 [color="#ED028C"] 
  E2->x6 [color="#ED028C"] 
  E1->E2 [color="blue"] 
  
  e1->x1
  e2->x2
  e3->x3
  e4->x4
  e5->x5
  e6->x6
  z2->E2}')
# Convert to SVG, then save as png
tmp = export_svg(tmp)
tmp = charToRaw(tmp) # flatten
rsvg_png(tmp, "img/sem3.png") # saved graph as png in current working directory
```
```{r , echo = FALSE, out.width = "180px",fig.align="center"}
knitr::include_graphics("img/sem3.png")
```

A SEM consists of two parts:

1. \color{blue}**Structural model**\color{black}: Regression-like relationships among the variables, working similar to *path analysis*

2. \color{magenta}**Measurement model** (or latent variable model)\color{black}: Relationships between OVs and LVs, working a little differently

\fontsize{5pt}{12}\selectfont
Notes: \newline
In this sense, we may say that a CFA model is a 'full SEM' whereas a path model is not \newline
A CFA is a SEM with just the measurement part (without the structural model)

## A new classification: From in/dependent to exo/endogenous variables

\fontsize{7pt}{12}\selectfont
In both SEM (e.g., CFA) and path models, the classic independent vs. dependent classification is replaced with a more meaningful one:

```{r echo=FALSE,message=FALSE,warning=FALSE}
library(DiagrammeR); library(DiagrammeRsvg); library(rsvg)
tmp <- grViz(
'digraph boxes_and_circles {
  graph [layout = neato]
  node [shape = oval]
  E1 [label = <&eta;<SUB>1</SUB>> pos="-0.5,0!" color="blue"]
  E2 [label = <&eta;<SUB>2</SUB>> pos="0.5,0!" color="#ED028C"]
  node [shape = box]
  x1 [label = <x<SUB>1</SUB>> pos="-2,1!" color="#ED028C"]
  x2 [label = <x<SUB>2</SUB>> pos="-2,0!" color="#ED028C"]
  x3 [label = <x<SUB>3</SUB>> pos="-2,-1!" color="#ED028C"]
  x4 [label = <x<SUB>4</SUB>> pos="2,1!" color="#ED028C"]
  x5 [label = <x<SUB>5</SUB>> pos="2,0!" color="#ED028C"]
  x6 [label = <x<SUB>6</SUB>> pos="2,-1!" color="#ED028C"]
  node [shape = plaintext]
  e1 [label = <&epsilon;<SUB>1</SUB>> pos="-3,1!"]
  e2 [label = <&epsilon;<SUB>2</SUB>>pos="-3,0!"]
  e3 [label = <&epsilon;<SUB>2</SUB>>pos="-3,-1!"]
  e4 [label = <&epsilon;<SUB>1</SUB>> pos="3,1!"]
  e5 [label = <&epsilon;<SUB>2</SUB>>pos="3,0!"]
  e6 [label = <&epsilon;<SUB>2</SUB>>pos="3,-1!"]
  z2 [label = <&zeta;<SUB>2</SUB>>pos="0.5,0.8!"]
  # edges
  E1->x1 
  E1->x2 
  E1->x3
  E2->x4
  E2->x5
  E2->x6
  E1->E2
  e1->x1
  e2->x2
  e3->x3
  e4->x4
  e5->x5
  e6->x6
  z2->E2}')
# Convert to SVG, then save as png
tmp = export_svg(tmp)
tmp = charToRaw(tmp) # flatten
rsvg_png(tmp, "img/sem4.png") # saved graph as png in current working directory
```
```{r , echo = FALSE, out.width = "180px",fig.align="center"}
knitr::include_graphics("img/sem4.png")
```

\fontsize{7.5pt}{12}\selectfont

- \color{blue}**Exogenous variables**\color{black}: variables (both OVs and LVs) without a direct 'cause' from inside the model (predictors), without error estimate \newline

- \color{magenta}**Endogenous variables**\color{black}: variables (both OVs and LVs) directly 'caused' from inside the model (predictors & outcomes), with error estimate $\epsilon$ (OV) or $\zeta$ (LV)

## A new starting point: From dataset columns to covariance matrices

\begincols
  \begincol{.5\textwidth}

\fontsize{7pt}{12}\selectfont
The starting point of LM(ER) is a vector (or a set of vectors) of variable values, usually corresponding to one or more columns from a dataset.
```{r , echo = FALSE}
data( earlymath, package = "ADati" )
rownames(earlymath) <- 1:nrow(earlymath)
df <- earlymath[,2:5]
```
```{r comment=NA}
head(df,4)
```

  \endcol
\begincol{.5\textwidth}

\fontsize{7pt}{12}\selectfont
The starting point of SEM and path models is the **covariance matrix of the observed variables**. \newline \color{blue} `r fontawesome::fa(name = "microscope", fill = "blue", height = "1em")` $cov(x,y) =\sum(x_i - \overline{x})(y_i-\overline{y})/N$ \color{black}
```{r eval=FALSE}
cov(df[,c("MAT","QI","WM","STM")])
```
```{r echo=FALSE,comment=NA}
round(cov(df[,c("MAT","QI","WM","STM")]),2)
```

  \endcol
\endcols

\color{white}_ \newline \color{black}

\fontsize{7.5pt}{12}\selectfont
SEM estimate a number of parameters $\theta$ so that the **implied covariance matrix** $\hat\sum(\theta)$ (i.e., the covariance matrix predicted by the model based on the parameter estimates) is as close as possible to the **sample covariance matrix** $S$ \newline

\fontsize{6pt}{12}\selectfont \color{blue}

`r fontawesome::fa(name = "microscope", fill = "blue", height = "1em")` Note: even the model parameters are estimated within **matrices of parameters** `r fontawesome::fa(name = "face-flushed", height = "1em")`

## Covariance & correlation

\fontsize{7.5pt}{12}\selectfont

>- __Variance__ = Expected value of the **squared deviation from the mean** of a random variable, or degree to which it deviates from its expected value \newline \color{blue}
`r fontawesome::fa(name = "microscope", fill = "blue", height = "1em")` $var(x) = \sigma^2_x =\frac{\sum(x_i -\overline{x})^2}{N}$ \color{black}

>- __Covariance__ = Measure of the **joint variability** of two random variables, or Degree to which they tend to deviate from their expected values in similar ways, either directly (positive cov) or inversely (negative cov), whose value depends on the variable scales of measurement (from $-\infty$ to $+\infty$) \newline \color{blue}
`r fontawesome::fa(name = "microscope", fill = "blue", height = "1em")` $cov(x_1,x_2) =\frac{\sum(x_{1i} - \overline{x_1})(x_{2i}-\overline{x_2})}{N}$ \color{black}

>- __Correlation__ = standardized covariance of two random variables \newline Correlation ranges from -1 (perfectly negative) to +1 (perfectly positive) \newline \color{blue} `r fontawesome::fa(name = "microscope", fill = "blue", height = "1em")` $cor(x_1,x_2) = \frac{cov(x_1,x_2)}{\sigma^2_{x_1}\sigma^2_{x_2}}$

```{r echo=FALSE,fig.width=9,fig.height=2,out.width="300px"}
par(mfrow=c(1,5))
x <- rnorm(mean=100,n=50,sd=1)
hist(x,main=paste("var =",round(var(x))),breaks=30,xlim=c(80,120))
x <- rnorm(mean=100,n=50,sd=10)
hist(x,main=paste("var =",round(var(x))),breaks=30,xlim=c(80,120))
x1 <- x
x2 <- x + rnorm(n=50,sd=10)
plot(x1~x2,
     main=paste("cov =",round(cov(x1,x2),2),"\ncor =",
                           round(cor(x1,x2),2)))
abline(lm(x1~x2),col="red")
x2 <- -x + rnorm(n=50,sd=10)
plot(x1~x2,
     main=paste("cov =",round(cov(x1,x2),2),"\ncor =",
                           round(cor(x1,x2),2)))
abline(lm(x1~x2),col="red")
x2 <- x + rnorm(n=50,sd=1000)
plot(x1~x2,
     main=paste("cov =",round(cov(x1,x2),2),"\ncor =",
                           round(cor(x1,x2),2)))
abline(lm(x1~x2),col="red")
```

## Covariance matrix (*S*)

\begincols
  \begincol{.45\textwidth}

\fontsize{7.5pt}{12}\selectfont
Given a set of *p* variables, we can define the covariance matrix:

$$S = \begin{bmatrix} s_{11}~~...,~~s_{1j}~~...~~s_{1p} \\ ...~~...~~...~~...~~... \\ s_{i1}~~...~~s_{ij}~~...~~s_{ip} \\ ...~~...~~...~~...~~... \\ s_{p1}~~...~~s_{pj}~~...~~s_{pp}\end{bmatrix}$$

```{r eval=FALSE}
cov(df[,c("MAT","QI","WM","STM")])
```

\fontsize{10.5pt}{12}\selectfont

```{r echo=FALSE,comment=NA}
round(cov(df[,c("MAT","QI","WM","STM")]),2)
```

  \endcol
\begincol{.6\textwidth}

\fontsize{10.5pt}{12}\selectfont

Properties of the covariance matrix:

1. __Symmetrical__: $s_{ij} = s_{ji}$

2. The **main diagonal** shows the **variances** (= covariance between each variable and itself)

  \endcol
\endcols

\color{white}_\color{black} \newline

\fontsize{7.5pt}{12}\selectfont
SEM estimate a number of parameters $\theta$ so that the **implied covariance matrix** $\hat\sum(\theta)$ (i.e., the covariance matrix predicted by the model based on the parameter estimates) is as close as possible to the **sample covariance matrix** $S$ 

## That's all for now!

\fontsize{8pt}{12}\selectfont 
__Questions?__ \newline

__Homework__ (optional):

- read the slides presented today \newline and write in the Moodle forum if you have any doubts

- **exe`r fontawesome::fa(name = "r-project", fill="#3333B2",height = "1em")`cises 12-13** from `exeRcises.pdf` \newline \newline

\fontsize{6pt}{12}\selectfont ____ \newline 
For each exercise, the solution (or one of the possible solutions) can be found in dedicated chunk of commented code within the `exeRcises.Rmd` file

# Resources

## Credits

\fontsize{8pt}{12}\selectfont
The present slides are partially based on: \fontsize{6pt}{12}\selectfont

- Altoè, G. (2023) Corso Modelli lineari generalizzati ad effetti misti - 2023. \color{blue} https://osf.io/b7tkp/ \color{black}

- Beaujean, A. A. (2014) Latent Variable Modeling Using R. A Step-by-Step Guide. New York: Routledge

- Finch, W. H., Bolin, J. E., Kelley, K. (2014). Multilevel Modeling Using R (2nd edition). Boca Raton: CRC Press

- Pastore, M. (2015). Analisi dei dati in psicologia (e applicazioni in R). Il Mulino.

- Pastore, M. (2021). Analisi dei dati in ambito di comunità

## Achronyms & Greek letters

\begincols
  \begincol{.45\textwidth}

\fontsize{6pt}{12}\selectfont

- CFA: confirmatory factor analysis

- LM: linear models/modeling

- LV: latent variable

- OV: observed variable

- SEM: structural equation models/modeling

>- SS: sum of squares

  \endcol
\begincol{.6\textwidth}

\fontsize{6pt}{12}\selectfont

- $\beta$ = *beta*, indexing path coefficients (or regression coefficients)

- $\epsilon$ = *epsilon*, indexing the error of an observed variable

- $\sigma$ = *sigma*, indexing the variance $\sigma^2$ of the errors $\epsilon$

- $\eta$ = *eta*, indexing latent variables

- $\theta$ = *theta*, indexing overall model parameters

>- ciao

  \endcol
\endcols