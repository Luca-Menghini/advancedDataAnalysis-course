---
title: 'ADVANCED DATA ANALYSIS \newline FOR PSYCHOLOGICAL SCIENCE'
subtitle: 'Homework exercises'
author:  |
 |
 | **Luca Menghini Ph.D.** \fontsize{9pt}{7.2}\selectfont
 |
 | luca.menghini@unipd.it
 |
 |
 | ***
 | Master degree in Developmental and Educational Psychology 
 |
 | University of Padova
 |
 | 2023-2024
 |
 | ![](img/logo.PNG){width=1.7in}
output:
  beamer_presentation:
    fonttheme: serif
    theme: Singapore
    slide_level: 2
    includes:
      in_header: mystyle_ex.tex
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE,tidy.opts = list(width.cutoff=80))
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = NA
)
library(Cairo)

```

## Some instructions to solve the exercises

\fontsize{7.5pt}{12}\selectfont
The present document includes some optional homework exercises on the contents presented during lectures. Similar to the course slides, exercises will be progressively updated as the course progresses.

To check the **exercise solutions**, just look at the `exeRcises.Rmd` file on either Github or Moodle: each exercise text is followed by a chunk of R code showing point-by-point solutions (or some among the many possible solutions).

If you have any doubts on how to solve the exercises, feel free to write me an e-mail or (even better) try writing in the **Moodle forum**, so that all students can see your question and try to reply it. We can also solve some exercise during lectures, but let me know! ;)

# LM

## 1. Correlation & regression

\fontsize{7.5pt}{12}\selectfont

For each couple of variables ($x,y$) generated as specified below:

a) represent univariate (boxplot) and bivariate distributions (scatter plot)

b) compute their correlation

c) use the `lm()` function to get the slope coefficient $\beta_1$ and determinate whether the relationship significantly differs from zero \newline

1. `y <- rnorm(50)` and `x1 <- y`

2. `x2 <- y + 10`

3. `x3 <- rnorm(50)`

4. `x4 <- x3 + 10`

5. Which conclusions can we draw? Which relationship between correlation and regression coefficient?

\fontsize{5.5pt}{12}\selectfont ____ \newline Source: Pastore, M. (2021). Analisi dei dati in contesti di comunità. Course held at the University of Padova, Academic Year 2021-2022.

```{r echo=FALSE,eval=FALSE}
# SOLUTION TO EXERCISE #1

rm(list=ls()) # emptying the work environment

# 1. y <- rnorm(50) and x1 <- y
y <- rnorm(50) # assigning values
x1 <- y
# a) univariate (boxplot) and bivariate distributions (scatter plot)
# par(mfrow=c(1,2)) # to have 2 graphs per plot
boxplot(y)
boxplot(x1) # boxplot: they are the same
# par(mfrow=c(1,1)) # to go back to 1 graph per plot
plot(y ~ x1) # scatter plot: perfectly correlated
# b) correlation
cor(x1,y) # r = 1 (perfect correlation)
# c) simple linear regression
fit <- lm(y ~ x1)
coefficients(fit) # when x1 = 0, y = 0; when x1 increases by 1 unit, y increases by 1 unit (they are the same)

# 2. x2 <- y + 10
x2 <- y + 10 # assigning values
# a) univariate (boxplot) and bivariate distributions (scatter plot)
# par(mfrow=c(1,2)) # to have 2 graphs per plot
boxplot(y)
boxplot(x2) # boxplot: same shape but centered on different values (0 vs. 10)
# par(mfrow=c(1,1)) # to go back to 1 graph per plot
plot(y ~ x2) # scatter plot: still perfectly correlated
# b) correlation
cor(x2,y) # r = 1 (perfect correlation)
# c) simple linear regression
fit <- lm(y ~ x2)
coefficients(fit) # when x1 = 0, y = -10; when x1 increases by 1 unit, y increases by 1 unit (perfect correlation)

# 3. x3 <- rnorm(50)
x3 <- rnorm(50) # assigning values
# a) univariate (boxplot) and bivariate distributions (scatter plot)
# par(mfrow=c(1,2)) # to have 2 graphs per plot
boxplot(y)
boxplot(x3) # boxplot: different shapes (y variates more) but both centered on zero
# par(mfrow=c(1,1)) # to go back to 1 graph per plot
plot(y ~ x3) # scatter plot: the correlation is no longer perfect
# b) correlation
cor(x3,y) # I got r = 0.03 but you might get a different value since y and x3 are randomly generated
# c) simple linear regression
fit <- lm(y ~ x3)
coefficients(fit) # I got b0 = -0.21 (when x3 = 0, y = -0.21) and b1 = 0.03 (when x increase by 1 unit, y increases by 0.03 units)

# 4. x4 <- x3 + 10
x4 <- x3 + 10 # assigning values
# a) univariate (boxplot) and bivariate distributions (scatter plot)
par(mfrow=c(1,2)) # to have 2 graphs per plot
boxplot(y)
boxplot(x4) # boxplot: different shapes (y variates more) and different central value (0 vs. 10)
# par(mfrow=c(1,1)) # to go back to 1 graph per plot
plot(y ~ x4) # scatter plot: the correlation is no longer perfect
# b) correlation
cor(x4,y) # I got r = 0.03 but you might get a different value since y and x3 are randomly generated
# c) simple linear regression
fit <- lm(y ~ x4)
coefficients(fit) # I got b0 = -0.56 (when x3 = 0, y = -0.56) and b1 = 0.03 (when x increase by 1 unit, y increases by 0.03 units)

# Which conclusions can we draw? Which relationship between correlation and regression coefficient?
# when two variables are identical or just differ by a constant (here, 10) their correlation is perfect
# in contrast, two randomly generated variables poorly correlate, regardless of the contrast between them
# in this particular case, where observations are randomly sampled from the normal distribution
  # the regression coefficients (slope) is almost identical to the Pearson correlation coefficient
```

## 2. LM assumptions & diagnostics

\fontsize{7.5pt}{12}\selectfont

Using the “*Pregnancy during pandemics*” data* that we saw in class, graphically evaluate the diagnostics of the selected model `m2`:

1. **Linearity**: are model residuals centered on zero?

2. **Normality**: are model residuals normally distributed?

3. **Homoscedasticity**: is residual variance constant over the levels of any predictor?

4. **Independence error-predictor**: are residuals unrelated to any predictor?

5. **Independence of observations**: based on the considered variables (`depr`, `threat`, `NICU`, and `age`), are individual observations independent?

6. **Absence of influential observations**: is there any observation that strongly influence the estimated coefficients?

7. **Absence of multicollinearity**: are predictors mutually unrelated?

\fontsize{5.5pt}{12}\selectfont ____ \newline *To read the dataset, you can either use the code in `2-multilevel.pdf` slide #10 or download the `pregnancy.RData` file from Moodle/Github ("data" folder) and use the command \color{blue} `load("pregnancy.RData")`

```{r echo=FALSE,eval=FALSE}
# SOLUTION TO EXERCISE #2

rm(list=ls()) # emptying the work environment

# loading data (from Github)
library(osfr) # package to interact with the Open Science Framework platform
proj <- "https://osf.io/ha5dp/" # link to the OSF project
osf_download(osf_ls_files(osf_retrieve_node(proj))[2, ],conflicts="overwrite") # download
preg <- na.omit(read.csv("OSFData_Upload_2023_Mar30.csv",stringsAsFactors=TRUE)) # read data
colnames(preg)[c(2,5,12,14)] <- c("age","depr","NICU","threat") # set variable names

# alternative way for loading data (from working directory, once you downloaded them from GitHub or Moodle)
load("4-data/pregnancy.RData") # (note: I saved the file in the "4-data" subfolder of my working directory)
head(preg) # showing first rows (the dataset is called 'preg')

# fitting model m2
m2 <- lm(depr ~ threat + NICU + age, data = preg)

# 1. linearity
hist(residuals(m2)) # histogram of residuals: residuals seem quite (although not perfectly) centered on zero (ok)

# 2. normality
hist(residuals(m2)) # histogram of residuals: seem quite (although not perfectly) normally distributed (ok)
qqnorm(residuals(m2)); qqline(residuals(m2)) # only some deviation from normality in the lower tale of the residual distribution (i.e., positive skewness) (ok, negligible)

# 3. heteroscedasticity
plot(residuals(m2)~preg$threat) # residual variance (spreadness of dots) does not seem to change over the values of threat (ok)
plot(residuals(m2)~preg$age) # residual variance (spreadness of dots) does not seem to change over the values of age (ok)
plot(residuals(m2)~preg$NICU) # residual variance (size of the boxes) does not seem to change between NICU levels (ok)

# 4. independence residuals - predictors
plot(residuals(m2)~preg$threat) # not a strong relationship between residuals and threat values (ok)
abline(lm(residuals(m2)~preg$threat),col="red") # to add a regression line
plot(residuals(m2)~preg$age) # not a strong relationship between residuals and age values (ok)
abline(lm(residuals(m2)~preg$age),col="red") # to add a regression line
plot(residuals(m2)~preg$NICU) # no substantial differences in residuals between NICU levels (ok)

# 5. independence of observations
# based on the considered variables, there are not uncontrolled factors that might account for local dependencies in the data (e.g., hospitals, cities, neighborhoods, etc.) (ok)

# 6. Absence of influential observations: is there any observation that strongly influence the estimated coefficients?
plot(m2,which=5) # no data points outside the Cook's distance cut-off region (which is not even included within the plot) (ok)

# 7. Absence of multicollinearity: Are predictors mutually unrelated?
cor(preg[,c("threat","age")]) # threat and age only correlate at r = 0.02 (low linear correlation)
library(car)
barplot(vif(m2),ylim=c(0,10)); abline(h=5,lty=2,col="red") # no VIF higher than 5 (ok)
```

## 3. Towards multilevel modeling

\fontsize{7.5pt}{12}\selectfont

1. Download and read the “*Adolescent insomnia*” dataset `INSA.RData` (Moodle/Github, "data" folder)

2. Explore the variables `dayNr` (day of assessment), `stress` (bedtime rating of daily stress), `insomnia` (categorical: insomnia vs. controls), and `TST` (total sleep time, in minutes) &rightarrow; mean, SD, frequencies, plots, and correlations

3. Fit a null model `m0` predicting `TST`

4. Fit a simple regression model `m1` predicting `TST` by `stress`

5. Fit a multiple regression model `m3` predicting `TST` by `stress` and `insomnia`

6. Compare the three models with the AIC and the likelihood ratio test

7. Print and interpret the coefficients (and their statistical significance) of the selected model

8. Now create two subsets of the `insa` dataset: `insa1` only including observations from the participant `s001` and `insa2` with observations from participant `s002`: how many rows in each dataset?

9. Repeat points 3-7 by using the two subsets: Are results consistent with what you found in the full sample?

```{r echo=FALSE,eval=FALSE}
# SOLUTION TO EXERCISE #3

rm(list=ls()) # emptying the work environment

# 1. loading data from Github
repo <- "https://github.com/SRI-human-sleep/INSA-home" # loading datasets from GitHub
load(url(paste0(repo,"/raw/main/Appendix%20D%20-%20Data/emaFINAL.RData")))
# alternatively, you can download the ema dataset from Github on Moodle, paste it in your working directory, and run the following lines (note: I saved the file in the "4-data" subfolder of my working directory):
load("4-data/insa.RData")

# 2. Explore the variables `dayNr`, `stress`, `insomnia`, and `TST`
# descriptives
mean(insa$dayNr,na.rm=T); sd(insa$dayNr,na.rm=T) # on average, 34 days per participant (SD = 21.2 days)
mean(insa$stress,na.rm=T); sd(insa$stress,na.rm=T) # on average, stress = 2.2 (over 5) (SD = 1)
table(insa$insomnia) # 3122 observations from the insomnia group, 3097 from the control group
mean(insa$TST,na.rm=T); sd(insa$TST,na.rm=T) # on average, 414 minutes of sleep (SD = 80.9 minutes)
# plots
par(mfrow=c(2,2)) # to have 4 graphs in 1 plot
hist(insa$dayNr) # skewed variable with most values being below 50 days, and a few values up to 350 days
hist(insa$stress) # skewed variables with most values being 1 or 2, and a few values being 5
plot(insa$insomnia) # quite balanced number of observations between groups
hist(insa$TST) # quite normally distributed variable
# correlations: very small positive correlation between TST and dayNr, very small negative correlation between stress and both dayNr and TST
cor(insa[,c("dayNr","stress","TST")],use="complete.obs")

# 3. Fit a null model `m0` predicting `TST`
m0 <- lm(TST ~ 1, data=insa[!is.na(insa$stress),]) # note: selecting only cases with nonmissing stress values, otherwise this and the following models will have a different sample size (by default, R uses all nonmissing observations)

# 4. Fit a simple regression model `m1` predicting `TST` by `stress`
m1 <- lm(TST ~ stress, data=insa)

# 5. Fit a multiple regression model `m3` predicting `TST` by `stress` and `insomnia`
m2 <- lm(TST ~ stress + insomnia, data=insa)

# 6. Compare the three models with the AIC and the likelihood ratio test
AIC(m0,m1,m2) # AIC: the lower the better -> best model is m2
lmtest::lrtest(m0,m1,m2) # both m1 and m2 are significant -> best model is m2

# 7. Print and interpret the coefficients (and their statistical significance) of the selected model
summary(m2)$coefficients
# when stress = 0 and insomnia = 0 (control group), the most expected TST value (mean) is 418.16 minutes, which is significantly higher than zero
# when insomnia = 0 (control group), a 1-unit increase in stress predicts a 3.3-minute decrease in TST, which is statistically significant
# when stress = 0, the insomnia group is predicted to show a mean TST of 5.46 higher than the control group, but this difference is not statistically significant 

# 8. subsample data from participant s001 and s002: how many rows?
insa1 <- insa[insa$ID=="s001",]
nrow(insa1) # 93 rows (days) from participant s001
insa2 <- insa[insa$ID=="s002",]
nrow(insa2) # 65 rows (days) from participant s002

# 9. Repeat points 3-7 by using the two subsets: Are results consistent with what you found in the full sample?
# s001
m0 <- lm(TST ~ 1, data = insa1[!is.na(insa1$stress),])
m1 <- lm(TST ~ stress, data = insa1)
# m2 <- lm(TST ~ stress + insomnia, data = insa1) # error! Because when we only sample 1 participant, then the insomnia variable does not variate --> so we do not consider model m2, but only m0 and m1
AIC(m0,m1) # m0 is better than m1
lmtest::lrtest(m0,m1) # m1 is not significantly better than m0
# s002
m0 <- lm(TST ~ 1, data = insa2[!is.na(insa2$stress),])
m1 <- lm(TST ~ stress, data = insa2)
AIC(m0,m1) # m0 is better than m1
lmtest::lrtest(m0,m1) # m1 is not significantly better than m0
# conclusion: if we only consider participant s001 or participant s002, the results are different than those obtained from the full sample (i.e., the relationship between stress and TST is no longer significant)
```

# LMER

## 4. Multilevel data structure {#ex4}

\fontsize{7.5pt}{12}\selectfont

1. Download and read the “*Innovative teaching program*” dataset `studentData.csv` (Moodle/Github, "data" folder)

2. Explore the student-level variables `studId` (identification code of each student), `math_grade` (student grade in math) and `anxiety` (anxiety level). What is the total number of students? How many rows per students? What is the range of `math_grade` and `anxiety`? 

3. How many students per class? How many students per level of the `tp` variable?

4. How many classes per level of the `tp` variable? \fontsize{6pt}{12}\selectfont To answer that, you can create the **wide-form dataset** by taking only one row per class (e.g., try using the `duplicated()` function preceded by the `!` symbol to remove duplicated values of `classID`) \fontsize{7.5pt}{12}\selectfont

5. Compute the mean `math_grade` and `anxiety` value for each class and join them to the wide-form dataset: which is the class with the maximum `math_grade`? Which class has the maximum `anxiety` level?

6. Fit a simple linear regression model predicting `math_grade` by `anxiety` both on the long-form and on the wide-form dataset; inspect and interpret the estimated coefficients and their statistical significance.

7. Which model has the highest standard errors? Why?

```{r echo=FALSE,eval=FALSE}
# SOLUTION TO EXERCISE #3

rm(list=ls()) # emptying the work environment

# 2. explore student-level variables: No. of students? 
table(itp$studID) # number of observations per student (1)
nrow(itp) # number of students = 90
mean(itp$math_grade); sd(itp$math_grade) # on average, participants took 8 in math (SD = 0.6)
mean(itp$anxiety); sd(itp$anxiety) # on average, participants reported anxiety levels of 3.11 (SD = 0.06)
summary(itp[,c("math_grade","anxiety")]) # math_grade ranges from 6.9 to 9.3; anxiety ranges from 3.01 to 3.41
 
# 3. How many students per class? How many students per level of the `tp` variable (teaching program)?
table(itp$classID) # from 11 to 30 students per class
table(itp$tp) # 52 students in the control group, 38 students in the intervention group

# 4. How may classes per tp level?
itp_wide <- itp[!duplicated(itp$classID),] # from long-form to wide-form: removing duplicated classID values
nrow(itp_wide)  # itp_wide only has 4 rows (1 row per cluster)
table(itp_wide$tp) # 2 classes per level of the tp variable (2 in the control, 2 in the intervention group)

# 5. mean math_grade and anxiety per class, which class has the maximum value?
mathGr <- aggregate(math_grade ~ classID, data=itp, FUN = mean) # math_grade by class
anx <- aggregate(anxiety ~ classID, data = itp, FUN = mean) # anxiety by class
mathGr[which(mathGr$math_grade==max(mathGr$math_grade)),] # class D has the maximum math_grade
mathGr[which(anx$anxiety==max(anx$anxiety)),] # class A has the maximum anxiety
itp_wide <- cbind(itp_wide,
                  math_grade_mean=mathGr$math_grade,
                  anxiety_mean=anx$anxiety) # joining mean values to the wide-form dataset
itp_wide # showing the wide-form dataset

# 6. predict math_grade by anxiety on both datasets, inspect and interpret coefficients
fit_long <- lm(math_grade ~ anxiety, data=itp) # long-form dataset (N = 90)
summary(fit_long)$coefficients 
# when student anxiety = 0, student math_grade is 17.7 (out of range*), which is significantly higher than zero
# when student anxiety increases by 1 unit, student math_grade decreases by 3.11 units, which is statistically significant
fit_wide <- lm(math_grade_mean ~ anxiety_mean, data=itp_wide) # wide-form dataset (N = 4)
summary(fit_wide)$coefficients
# when class anxiety = 0, class math-grade is 63.44 (out of range*), which is significantly higher than zero
# when class anxiety increases by 1 unit, class math-grade decreases by 17.76, which is statistically significant

# *intercepts are out of range because predictors are not centered
# that is, since intercepts are estimated for anxiety = 0 (which is not possible), the model returns an impossible (i.e., out-of-range) value

# 7. which model has the highest standard errors? Why?
# the model fitted on the wide-form dataset (N = 4) shows the highest standard error (i.e., parameters are estimated with a poor precision) because the model uses a lower sample size (N = 4) compared to that used by the other model (N = 90)
```

## 5. Data centering

\fontsize{7.5pt}{12}\selectfont

Consider the long- and wide-form datasets from \color{blue}[exercise #4](#ex4)\color{black}:

1. Compute the **grand-mean-centered** `anxiety` values from the wide-form dataset

2. Fit a simple linear model predicting class-level `math_grade` by grand-mean-centered `anxiety` using the wide-form dataset. Inspect and interpret the estimated coefficients, and compare them with those estimated in the previous exercise

3. Use the `join()` function from the `plyr` package to join the cluster-level mean `anxiety` values to the long-form dataset

4. Compute the **cluster-mean-centered** `anxiety` values by subtracting mean class `anxiety` from student-level `anxiety`

5. Considering class `A`, how many students have an `anxiety` level below the class average? How many have a higher value than the average?

6. Fit a simple linear model predicting student-level `math_grade` by cluster-mean-centered `anxiety` values using the long-form dataset. Inspect and intepret the estimated coefficients, and compare them with those estimated in the previous exercise

```{r echo=FALSE,eval=FALSE}
# SOLUTION TO EXERCISE #5

# 1. grand-mean-centered anxiety from the wide-form dataset (which I called "itp_wide" in exercise #4)
itp_wide$anxiety.gmc <- itp_wide$anxiety_mean - mean(itp_wide$anxiety_mean)
itp_wide[,c("anxiety_mean","anxiety.gmc")] # showing uncentered and centered values

# 2. linear model predicting math_grade by grand-mean-centered anxiety in the wide-form dataset
fit_wide.cmc <- lm(math_grade_mean ~ anxiety.gmc, data = itp_wide)
summary(fit_wide)$coefficients # coefficients from the uncentered model (which I called "fit_wide" in ex #4)
summary(fit_wide.cmc)$coefficients # coefficients from the centered model
# intercept changed from 63.4 to 8.13 (now it's on range!), but still significantly higher than zero
# the slope is basically the same, still significantly lower than zero

# 3. join cluster-level mean anxiety to the long-form dataset
library(plyr)
itp <- join(itp, # selecting long-form dataset
            itp_wide[,c("classID","anxiety_mean")], # selecting the columns of interest from the wide-form dataset
            by="classID") # joining by classID
itp[,c("anxiety","anxiety_mean")] # showing individual-level and cluster-level anxiety

# 4. cluster-mean-centered anxiety from the long-form dataset
itp$anxiety.cmc <- itp$anxiety - itp$anxiety_mean
itp[,c("anxiety","anxiety_mean","anxiety.cmc")] # showing ind-level, clust-level, and clust-mean-centered anxiety

# 5. Focusing on class A, how many student anxiety values below/above the class average?
classA <- itp[itp$classID=="A",] # subsetting data from class A
nrow(classA[classA$anxiety < mean(classA$anxiety),]) # 16 with math_grade below the class average
nrow(classA[classA$anxiety.cmc < 0,]) # alternative way based on cluster-mean-centered values (i.e., average = 0)
nrow(classA[classA$anxiety > mean(classA$anxiety),]) # 14 with math_grade above the class average
nrow(classA[classA$anxiety.cmc > 0,]) # alternative way based on cluster-mean-centered values (i.e., average = 0)

# 6. linear model predicting math_grade by cluster-mean-centered `anxiety` values
fit_long.cmc <- lm(math_grade ~ anxiety.cmc, data = itp) 
summary(fit_long)$coefficients # coefficients from the uncentered model (which I called "fit_long" in ex #4)
summary(fit_long.cmc)$coefficients # coefficients from the centered model
# intercept changed from 17.75 to 8.05 (now it's on range!), but still significantly higher than zero
# the slope changed from -3.11 to -2.20, still significantly lower than zero
```

## 6. Data centering & level-specific correlations {#ex6}

\fontsize{7.5pt}{12}\selectfont
Do left- and right-side infant pupil sizes correlate more at the within-subject or at the between-subject level?

1. Download and read the "*Infant pupil*" dataset `infantPupil.csv`

2. Subset columns 15, 10, 11, 12, and 13, and rename them as `ID` (subject identification code), `pupil.left` (left-side pupil size in mm), `pupil.left_valid` (validity of left-sized pupil size measurement), `pupil.right` (right-side pupil size in mm), and `pupil.right_valid` (validity of the right-side pupil size measurement)

3. How many valid cases for each eye? (note: 1 = valid, 0 = invalid)

4. Remove all cases with invalid pupil size in either one or the other eye 

5. Compute the cluster means and the cluster-mean-centered values for `pupil.left` and `pupil.right` 

6. Compute the between-subject and the within-subject correlations between the two variables: Do left- and right-side infant pupil sizes correlate more at the within-subject or at the between-subject level?

```{r echo=FALSE,eval=FALSE}
# SOLUTION TO EXERCISE #6

rm(list=ls()) # emptying work environment

# 1. reading infant pupil dataset (note: I saved the file in the 'data' subfolder in my working dir)
pupil <- read.csv2("data/infantPupil.csv") # use read.csv2 for columns separated by ";" (csv2) rather than "," (csv)

# 2. subsetting and renaming columns
pupil <- pupil[,c(15,10:13)]
colnames(pupil) <- c("ID","pupil.left","pupil.left_valid","pupil.right","pupil.right_valid")
summary(as.factor(pupil$pupil.left_valid))

# 3. How many valid cases?
table(pupil$pupil.left_valid) # 16,379 valid left
100*table(pupil$pupil.left_valid)/nrow(pupil) # percentage (65%)
table(pupil$pupil.right_valid) # 15,337 valid right
100*table(pupil$pupil.right_valid)/nrow(pupil) # percentage (60.5%)

# 4. removing invalid cases in either eye
pupil <- pupil[pupil$pupil.right_valid==1 & pupil$pupil.left_valid==1,]

# 5. cluster means and cluster mean centered
wide <- aggregate(pupil.left ~ ID, data=pupil, FUN=mean) # cluster mean of pupil.left
# I got Warning: argument is not numeric or logical (i.e., pupile sizes are considered as characters)
pupil$pupil.left <- as.numeric(pupil$pupil.left) # converting to numeric
pupil$pupil.right <- as.numeric(pupil$pupil.right)
wide <- aggregate(pupil.left ~ ID, data=pupil, FUN=mean) # now it works
wide # let's take a look
pupil <- plyr::join(pupil,wide,by="ID") # joining cluster means to long-form dataset
colnames(pupil)[6] <- "pupil.left.cm" # renaming variable to avoid duplicated column names
pupil$pupil.left.cmc <- pupil$pupil.left - pupil$pupil.left.cm # cluster mean centering

# same operations for pupil.right
wide <- aggregate(pupil.right ~ ID, data=pupil, FUN=mean) 
pupil <- plyr::join(pupil,wide,by="ID")
colnames(pupil)[8] <- "pupil.right.cm"
pupil$pupil.right.cmc <- pupil$pupil.right - pupil$pupil.right.cm 

# 6. level-specific correlations
pupil_wide <- pupil[!duplicated(pupil$ID),] # taking only one row per subject
# between-subject correlation (between cluster means from the wide-form dataset)
cor(pupil_wide$pupil.left.cm, # r = 0.987
    pupil_wide$pupil.right.cm) 
# within-subject correlation (between cluster-mean-centered values from the long-form dataset)
cor(pupil$pupil.left.cmc, # r = 0.865
    pupil$pupil.right.cmc)

# 7. Do left- and right-side infant pupil sizes correlate more at the within-subject or at the between-subject level?
# they seem to correlate more at the between-subject level!
```

## 7. Intraclass correlation coefficient

\fontsize{8.5pt}{12}\selectfont
Using data from \color{blue}[exercise #6](#ex6)\color{black}, compute the intraclass correlation coefficient (ICC) for both pupil size measures.

1. Do they variate more at the within-subject (lv1) or at the between-subject (lv2) level?

2. What is the percentage of within-subject variability over the total variability?

3. Does one eye variate more within-subject than the other?

```{r echo=FALSE,eval=FALSE}
# SOLUTION TO EXERCISE #7

# first, you can run all the commands used in exercise #6

# computing left-side pupil size ICC from null LMER model
library(lme4) # package for fitting LMER models
m0.left <- lmer(pupil.left ~ (1|ID), data=pupil) # null LMER model
tau2.left <- summary(m0.left)$varcor$ID[[1]] # extracting the random intercept variance tau2
sigma2.left <- summary(m0.left)$sigma^2 # extracting the residual variance sigma2
ICC.left <- tau2.left/(tau2.left + sigma2.left) # ICC = var between / total var = tau2 / (tau2 + sigma2)
ICC.left # 0.60

# computing ICC for right-side pupil size
m0.right <- lmer(pupil.right ~ (1|ID), data=pupil) # null LMER model
tau2.right <- summary(m0.right)$varcor$ID[[1]] # tau2
sigma2.right <- summary(m0.right)$sigma^2 # sigma2
ICC.right <- tau2.right/(tau2.right + sigma2.right) # ICC
ICC.right # 0.64

# 1. Do they variate more at the within-subject (lv1) or at the between-subject (lv2) level?
# ICC range from .60 (i.e., 60% of variance at the between level) to .64 (i.e., 64% of variance at the between level), so they variate more at the between-subject level (lv2) than at the within-subject level (lv1)

# 2. What is the percentage of within-subject variability over the total variability?
# we simply need to compute 1 - ICC
1 - ICC.left # left side: 39% of within-subject variability
1 - ICC.right # right side: 36% of within-subject variability

# 3. Does one eye variate more within-subject than the other?
# yes, left-side pupil size variates within-subject variability is 3% higher than right-side pupil size
# however, we don't know whether this difference might be substantial or not
```